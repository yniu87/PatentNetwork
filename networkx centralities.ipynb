{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe from csv file\n",
    "cumsum = pd.read_csv('../Citation_data/citation_cumsum.csv')\n",
    "cumsum.drop(columns=['cited_subcategory_id'], inplace=True)\n",
    "cumsum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11.0': 54397.0, '12.0': 198870, '13.0': 128978.0, '14.0': 249712, '15.0': 567106.0, '19.0': 2089469.0, '21.0': 3407899, '22.0': 2559830, '23.0': 808556, '24.0': 1303659, '25.0': 754633, '31.0': 1616664, '32.0': 4465029, '33.0': 67152.0, '39.0': 594492.0, '41.0': 795397.0, '42.0': 478940.0, '43.0': 670097.0, '44.0': 325938, '45.0': 1094896, '46.0': 1910726, '49.0': 686175, '51.0': 783994.0, '52.0': 328012.0, '53.0': 709986.0, '54.0': 408838, '55.0': 750593, '59.0': 1113577.0, '61.0': 424898, '62.0': 685177, '63.0': 309460.0, '64.0': 642054.0, '65.0': 517552.0, '66.0': 166618.0, '67.0': 127906.0, '68.0': 387990.0, '69.0': 1676400, '70.0': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary of node weights\n",
    "node_weights = dict()\n",
    "row_number = 0\n",
    "for node in list(cumsum.columns):\n",
    "    node_weights[node] = cumsum.at[row_number, node]\n",
    "    row_number += 1\n",
    "print(node_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('11.0', {'weight': 54397.0}),\n",
       " ('12.0', {'weight': 198870}),\n",
       " ('13.0', {'weight': 128978.0}),\n",
       " ('14.0', {'weight': 249712}),\n",
       " ('15.0', {'weight': 567106.0}),\n",
       " ('19.0', {'weight': 2089469.0}),\n",
       " ('21.0', {'weight': 3407899}),\n",
       " ('22.0', {'weight': 2559830}),\n",
       " ('23.0', {'weight': 808556}),\n",
       " ('24.0', {'weight': 1303659}),\n",
       " ('25.0', {'weight': 754633}),\n",
       " ('31.0', {'weight': 1616664}),\n",
       " ('32.0', {'weight': 4465029}),\n",
       " ('33.0', {'weight': 67152.0}),\n",
       " ('39.0', {'weight': 594492.0}),\n",
       " ('41.0', {'weight': 795397.0}),\n",
       " ('42.0', {'weight': 478940.0}),\n",
       " ('43.0', {'weight': 670097.0}),\n",
       " ('44.0', {'weight': 325938}),\n",
       " ('45.0', {'weight': 1094896}),\n",
       " ('46.0', {'weight': 1910726}),\n",
       " ('49.0', {'weight': 686175}),\n",
       " ('51.0', {'weight': 783994.0}),\n",
       " ('52.0', {'weight': 328012.0}),\n",
       " ('53.0', {'weight': 709986.0}),\n",
       " ('54.0', {'weight': 408838}),\n",
       " ('55.0', {'weight': 750593}),\n",
       " ('59.0', {'weight': 1113577.0}),\n",
       " ('61.0', {'weight': 424898}),\n",
       " ('62.0', {'weight': 685177}),\n",
       " ('63.0', {'weight': 309460.0}),\n",
       " ('64.0', {'weight': 642054.0}),\n",
       " ('65.0', {'weight': 517552.0}),\n",
       " ('66.0', {'weight': 166618.0}),\n",
       " ('67.0', {'weight': 127906.0}),\n",
       " ('68.0', {'weight': 387990.0}),\n",
       " ('69.0', {'weight': 1676400}),\n",
       " ('70.0', {'weight': 0.0})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create graph and add nodes\n",
    "G = nx.MultiDiGraph()\n",
    "G.clear()\n",
    "for node in list(cumsum.columns):\n",
    "    G.add_node(node, weight=node_weights[node])\n",
    "list(G.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add edges with weights\n",
    "row_number = 0\n",
    "for node_1 in list(cumsum.columns):\n",
    "    for node_2 in list(cumsum.columns):\n",
    "        if str(node_1) != str(node_2):\n",
    "            G.add_edge(node_1, node_2, weight=cumsum.at[row_number, node_2])\n",
    "    row_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[527.4398134688881, 978.3135777651519, 790.5185574503977, 1096.7298201763829, 1672.0998799398658, 3344.375203364958, 4357.5453846612045, 3731.761257323396, 2014.525560892734, 2596.3951912386347, 1942.505419025952, 2913.411149178037, 5047.055975683728, 580.5066668328591, 1713.8341345532633, 1997.152286921412, 1531.2375692042997, 1824.8175084580416, 1255.7203907381434, 2365.724753983978, 3187.128264786872, 1847.6876943183663, 1981.9937998453295, 1259.8002140905267, 1881.12469473946, 1410.7759821821628, 1937.0188664743969, 2387.120407839884, 1439.1364338351095, 1846.2750675975242, 1222.8864601549146, 1784.3356552460427, 1594.234928321316, 896.0798302330775, 787.3241771522488, 1373.2107468033835, 2970.698514280868, 100.0]\n"
     ]
    }
   ],
   "source": [
    "#Customize node and edge sizes according to size of internal and external linkage\n",
    "row_number = 0\n",
    "size_list = []\n",
    "edge_list = []\n",
    "for node in list(cumsum.columns):\n",
    "    size_list.append(abs((cumsum.at[row_number, node])**(1/1.8)) + 100)\n",
    "    row_number += 1\n",
    "print(size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate edge betweenness centrality\n",
    "ebc = nx.edge_betweenness_centrality(G, weight='node_weights') #is this weight right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Read in data\n",
    "string = '../Citation_data/5_year_citation_snapshot' \n",
    "csv = '.csv'\n",
    "year = np.array([1980, 1985, 1990, 1995, 2000, 2005, 2010])\n",
    "\n",
    "d = {}\n",
    "for y in year:\n",
    "    fName = string + str(y) + csv \n",
    "    \n",
    "    #Create a dataframe\n",
    "    temp = pd.read_csv(fName)\n",
    "    temp.drop(columns=['cited_subcategory_id'], inplace=True)\n",
    "    \n",
    "    #Create dictionary of node weights\n",
    "    node_weights = dict()\n",
    "    row_number = 0\n",
    "    for node in list(temp.columns):\n",
    "        node_weights[node] = temp.at[row_number, node]\n",
    "        row_number += 1\n",
    "    \n",
    "    #Create graph and add nodes\n",
    "    G = nx.MultiDiGraph()\n",
    "    G.clear()\n",
    "    for node in list(temp.columns):\n",
    "        G.add_node(node, weight=node_weights[node])\n",
    "    list(G.nodes(data=True))\n",
    "    \n",
    "    #Add edges with weights\n",
    "    row_number = 0\n",
    "    for node_1 in list(temp.columns):\n",
    "        for node_2 in list(temp.columns):\n",
    "            if str(node_1) != str(node_2):\n",
    "                G.add_edge(node_1, node_2, weight=temp.at[row_number, node_2])\n",
    "        row_number += 1\n",
    "    \n",
    "    #Customize node and edge sizes according to size of internal and external linkage\n",
    "    row_number = 0\n",
    "    size_list = []\n",
    "    edge_list = []\n",
    "    for node in list(temp.columns):\n",
    "        size_list.append(abs((temp.at[row_number, node])**(1/1.8)) + 100)\n",
    "        row_number += 1\n",
    "    \n",
    "    #Calculate edge betweenness centrality\n",
    "    name = 'ebc' + str(y)\n",
    "    d[name] = nx.edge_betweenness_centrality(G, weight='node_weights') #is this weight correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if weights were properly added, if they are, this should be false\n",
    "d['ebc1980']==d['ebc1985']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
